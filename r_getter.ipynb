{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r_getter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgiUVplY8TsbV5wqjT8i5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reckoning-machines/sec_text_nlp/blob/master/r_getter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxREunso0REA",
        "colab_type": "code",
        "outputId": "d643cb24-c075-4e9b-e5d5-7ac3439a829b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# why use R here?  \n",
        "# edgarWebR pulls sections really well\n",
        "# do i want to find a python library for the same thing?  sure.\n",
        "# do i want to write a python utils file for the same thing?  not really but we may have to!\n",
        "\n",
        "#first pull the ticker list with google drive handler lib\n",
        "!git clone https://gist.github.com/dc7e60aa487430ea704a8cb3f2c5d6a6.git /tmp/colab_util_repo\n",
        "!mv /tmp/colab_util_repo/colab_util.py colab_util.py \n",
        "!rm -r /tmp/colab_util_repo\n",
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()\n",
        "\n",
        "#drive_handler.download('test_ticker_list.csv', target_path='test_ticker_list.csv')\n",
        "drive_handler.download('implementation_ticker_list.csv', target_path='implementation_ticker_list.csv')\n",
        "\n",
        "#import pandas as pd\n",
        "df_tickers = pd.read_csv('implementation_ticker_list.csv')\n",
        "df_tickers = df_tickers[df_tickers['Symbol']=='FRC']\n",
        "df_tickers.to_csv('implementation_ticker_list.csv')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/colab_util_repo'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n",
            "Unpacking objects:   2% (1/40)   \rUnpacking objects:   5% (2/40)   \rUnpacking objects:   7% (3/40)   \rUnpacking objects:  10% (4/40)   \rUnpacking objects:  12% (5/40)   \rUnpacking objects:  15% (6/40)   \rUnpacking objects:  17% (7/40)   \rUnpacking objects:  20% (8/40)   \rUnpacking objects:  22% (9/40)   \rUnpacking objects:  25% (10/40)   \rUnpacking objects:  27% (11/40)   \rUnpacking objects:  30% (12/40)   \rUnpacking objects:  32% (13/40)   \rUnpacking objects:  35% (14/40)   \rUnpacking objects:  37% (15/40)   \rUnpacking objects:  40% (16/40)   \rUnpacking objects:  42% (17/40)   \rUnpacking objects:  45% (18/40)   \rUnpacking objects:  47% (19/40)   \rUnpacking objects:  50% (20/40)   \rUnpacking objects:  52% (21/40)   \rUnpacking objects:  55% (22/40)   \rUnpacking objects:  57% (23/40)   \rUnpacking objects:  60% (24/40)   \rUnpacking objects:  62% (25/40)   \rUnpacking objects:  65% (26/40)   \rUnpacking objects:  67% (27/40)   \rUnpacking objects:  70% (28/40)   \rUnpacking objects:  72% (29/40)   \rUnpacking objects:  75% (30/40)   \rUnpacking objects:  77% (31/40)   \rUnpacking objects:  80% (32/40)   \rUnpacking objects:  82% (33/40)   \rUnpacking objects:  85% (34/40)   \rUnpacking objects:  87% (35/40)   \rUnpacking objects:  90% (36/40)   \rUnpacking objects:  92% (37/40)   \rUnpacking objects:  95% (38/40)   \rUnpacking objects:  97% (39/40)   \rUnpacking objects: 100% (40/40)   \rUnpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jdag6BhSmY",
        "colab_type": "code",
        "outputId": "b781331b-245e-40e8-da80-1041319f23b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# activate R magic\n",
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The rpy2.ipython extension is already loaded. To reload it, use:\n",
            "  %reload_ext rpy2.ipython\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x4-h6m0x-V",
        "colab_type": "code",
        "outputId": "1f2b2069-0bff-45b2-9e9a-d43072553c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "#R GETTER.  For this example, only one ticker (head,1) is pulled \n",
        "#file is saved into local \n",
        "#then python code cell pushes file to google sheet\n",
        "#devtools::install_github(\"tidyverse/googlesheets4\")\n",
        "\n",
        "#devtools::install_version(\"xml2\", version = \"1.2.2\", repos = \"http://cran.us.r-project.org\")\n",
        "#file creates a set of csv from ticker list which include metadata & text data.\n",
        "\n",
        "\n",
        "  #devtools::install_packages('trinker/textclean')\n",
        "  devtools::install_github(\"mwaldstein/edgarWebR\")\n",
        "  devtools::install_github(\"r-lib/xml2\") #this for edgarWebR \n",
        "  devtools::install_github('trinker/textclean')\n",
        "\n",
        "  library(edgarWebR) #this is an up to date library with an active maintainer.\n",
        "  library(xml2)\n",
        "  library(knitr)\n",
        "  library(dplyr)\n",
        "  library(purrr)\n",
        "  library(rvest)\n",
        "  library(tidyr)\n",
        "  library(readr)\n",
        "  #library(textshape)\n",
        "  #library(lexicon)\n",
        "  library(textclean)\n",
        "\n",
        "\n",
        "  LOGFILE = format(Sys.time(), \"%b_%d_%Y.log\")\n",
        "  print(LOGFILE)\n",
        "\n",
        "  CSVFILE = format(Sys.time(), \"%b_%d_%Y.csv\")\n",
        "  print(CSVFILE)\n",
        "\n",
        "  get_filings_links <-function(str_ticker) {\n",
        "    df_filings <- company_filings(str_ticker, type = \"10-\", count = 20)\n",
        "    df_filings <- df_filings[df_filings$type == \"10-K\" | df_filings$type == \"10-Q\", ]\n",
        "    df_filing_infos <- map_df(df_filings$href, filing_information)\n",
        "    df_filings <- bind_cols(df_filings, df_filing_infos)\n",
        "    return(head(as_tibble(df_filings),12))\n",
        "  }\n",
        "\n",
        "  write_log <- function(str_text) {\n",
        "      print(str_text)\n",
        "      if (file.exists(LOGFILE)) {\n",
        "          write(str_text,file=LOGFILE,append=TRUE)\n",
        "      } else {\n",
        "          write(str_text,file=LOGFILE,append=FALSE)\n",
        "      }\n",
        "\n",
        "  }\n",
        "\n",
        "  write_log_csv <- function(df) {\n",
        "      if (file.exists(CSVFILE)) {\n",
        "          write_csv(df,CSVFILE,append=TRUE)\n",
        "      } else {\n",
        "          write_csv(df,CSVFILE,append=FALSE)\n",
        "      }\n",
        "\n",
        "  }"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Skipping install of 'edgarWebR' from a github remote, the SHA1 (e7fa70ea) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\n",
            "R[write to console]: Skipping install of 'xml2' from a github remote, the SHA1 (876759f3) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\n",
            "R[write to console]: Skipping install of 'textclean' from a github remote, the SHA1 (184d7868) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1] \"May_18_2020.log\"\n",
            "[1] \"May_18_2020.csv\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYcX52F7_pu",
        "colab_type": "code",
        "outputId": "4cbc9e12-1566-46b3-a803-94add9c70177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "get_mdna_text <- function(str_href) {\n",
        "  write_log(str_href)\n",
        "  \n",
        "  #default search\n",
        "  str_section = 'item 2|item 7'\n",
        "  str_search = 'discussion'  \n",
        "  \n",
        "  df_filing_documents <- filing_documents(str_href) %>%\n",
        "    filter(!grepl('.pdf',href))\n",
        "\n",
        "  str_doc_href <- df_filing_documents[df_filing_documents$type == \"10-K\" | df_filing_documents$type == \"10-Q\",]$href\n",
        "  doc <- parse_filing(str_doc_href)\n",
        "\n",
        "  #return(doc)\n",
        "    \n",
        "  df_txt <- doc[grepl(str_section, doc$item.name, ignore.case = TRUE) & grepl(str_search, doc$item.name, ignore.case = TRUE), ] # only discussion for now\n",
        "  #if default search fails, use a dictionary attempt\n",
        "  if (nrow(df_txt) == 0) {\n",
        "    write_log('going to backup')\n",
        "    # paired vector of start and ending text to slice if found\n",
        "\n",
        "    #JPM and #ECL\n",
        "    vec_start_end <- c('EXECUTIVE OVERVIEW'='CONSOLIDATED RESULTS OF OPERATIONS',\n",
        "                       'The following management discussion and analysis'='NON-GAAP FINANCIAL MEASURES',\n",
        "                       'CURRENT ECONOMIC CONDITIONS'='FORWARD-LOOKING STATEMENTS')\n",
        "    \n",
        "    #this would be case sensitive\n",
        "    for (start_text in names(vec_start_end)) {\n",
        "      \n",
        "      end_text = as.character(vec_start_end[start_text])\n",
        "      \n",
        "      write_log(paste0('trying ',start_text))\n",
        "      write_log(paste0('to ',end_text))\n",
        "      \n",
        "      i_start = as.integer(which(grepl(start_text, doc$text))) #this should be a loop for each dictionary item\n",
        "      i_end = as.integer(which(grepl(end_text, doc$text)))\n",
        "      \n",
        "      \n",
        "      write_log(i_start)\n",
        "      write_log(i_end)\n",
        "      \n",
        "      #return(i_start)\n",
        "      \n",
        "      if (length(i_start) != 0 & length(i_end) != 0) {\n",
        "        df_txt = doc[i_start:i_end,]\n",
        "      }\n",
        "      \n",
        "    }\n",
        "    \n",
        "  }\n",
        "  #we could do some text preprocessing here.\n",
        "  \n",
        "  df_txt <- as_tibble(df_txt) %>%\n",
        "    #mutate(text = textclean::strip(text)) %>%\n",
        "    mutate(section = str_search)\n",
        "  \n",
        "  return(df_txt)\n",
        "}\n",
        "\n",
        "get_section_text <- function(str_href, str_section, str_search) {\n",
        "  write_log(str_href)\n",
        "  \n",
        "  df_filing_documents <- filing_documents(str_href)\n",
        "  str_doc_href <- df_filing_documents[df_filing_documents$type == \"10-K\" | df_filing_documents$type == \"10-Q\",]$href\n",
        "  doc <- parse_filing(str_doc_href)\n",
        "  \n",
        "  df_txt <- doc[grepl(str_section, doc$item.name, ignore.case = TRUE) & grepl(str_search, doc$item.name, ignore.case = TRUE), ] # only discussion for now\n",
        "  #we could do some text preprocessing here.\n",
        "  \n",
        "  df_txt <- as_tibble(df_txt) %>%\n",
        "    mutate(text = textclean::strip(text)) %>%\n",
        "    mutate(section = str_search)\n",
        "  \n",
        "  return(df_txt)\n",
        "}\n",
        "\n",
        "\n",
        "get_document_text <- function(str_ticker, force = FALSE) { #not using force yet\n",
        "  start_time <- Sys.time()\n",
        "  \n",
        "  write_log(str_ticker)\n",
        "  \n",
        "  str_write_name <- paste0('sec_data_folder/',str_ticker)\n",
        "  \n",
        "  write_log(\"get filings links ...\")\n",
        "  \n",
        "  df_filings <- get_filings_links(str_ticker) %>% \n",
        "        mutate(ticker = str_ticker)\n",
        "  \n",
        "  write_log_csv(df_filings)\n",
        "\n",
        "#for debug\n",
        "  i_test = nrow(df_filings) #for some reason this won't evaulate inside the if statement\n",
        "  if (i_test == 0) {\n",
        "      return(NULL)\n",
        "  }\n",
        "\n",
        "  write_log(\"get section text ...\")\n",
        "  \n",
        "  df_data <- (df_filings) %>% \n",
        "    rowwise() %>%\n",
        "    mutate(nest_discussion = map(.x = href, .f = get_mdna_text)) %>%\n",
        "    ungroup() %>%\n",
        "    group_by(period_date) %>%\n",
        "    arrange(desc(period_date))\n",
        "  \n",
        "  #jenky - find a rowwise application\n",
        "  a <- df_data %>% \n",
        "    select(period_date,filing_date,type,form_name,documents,nest_discussion) %>%\n",
        "    unnest(nest_discussion)\n",
        "\n",
        "  write_log(\"write to local csv  ...\")\n",
        "  df_data <- a %>%\n",
        "    as_tibble() %>%\n",
        "    write_csv(paste0(str_write_name,\".csv\"))\n",
        "  \n",
        "  end_time <- Sys.time()\n",
        "  \n",
        "  write_log(end_time - start_time)\n",
        "  \n",
        "  return(df_data)\n",
        "}\n",
        "\n",
        "#long run.\n",
        "df_tickers <- read_csv('implementation_ticker_list.csv')\n",
        "dir.create('sec_data_folder', showWarnings = FALSE)\n",
        "\n",
        "#file creates a set of csv from ticker list which include metadata & text data.\n",
        "df_tickers <- (df_tickers)\n",
        "\n",
        "df_data <- map_df(df_tickers$Symbol, get_document_text)\n",
        "#print(head(df_data))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Parsed with column specification:\n",
            "cols(\n",
            "  X1 = col_double(),\n",
            "  `Unnamed: 0` = col_double(),\n",
            "  Symbol = col_character(),\n",
            "  Security = col_character(),\n",
            "  `SEC filings` = col_character(),\n",
            "  `GICS Sector` = col_character(),\n",
            "  `GICS Sub Industry` = col_character(),\n",
            "  `Headquarters Location` = col_character(),\n",
            "  `Date first added` = col_date(format = \"\"),\n",
            "  CIK = col_double(),\n",
            "  Founded = col_double(),\n",
            "  mkt_cap = col_double()\n",
            ")\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1] \"FRC\"\n",
            "[1] \"get filings links ...\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuyztVzxz7uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4BkP1_E2F0H",
        "colab_type": "code",
        "outputId": "7cec2e0e-59da-4850-a135-b8febaeb6133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#push files to google drive\n",
        "import os.path\n",
        "from os import path\n",
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()\n",
        "\n",
        "sec_folder_id = drive_handler.create_folder('sec_data_folder')\n",
        "\n",
        "import pandas as pd\n",
        "df_tickers = pd.read_csv('implementation_ticker_list.csv')\n",
        "\n",
        "for i, row in df_tickers.iterrows():\n",
        "  str_ticker = row['Symbol']\n",
        "  \n",
        "  print('working for:'+str_ticker+\".csv ...\")\n",
        "\n",
        "  str_to_file = 'sec_data_folder'\n",
        "  str_from_file = 'sec_data_folder/'+str_ticker+'.csv'\n",
        "\n",
        "  if path.exists(str_from_file): # a rare example of error handling\n",
        "    drive_handler.upload(str_from_file, parent_path=str_to_file,overwrite = True)\n",
        "\n",
        "print(\"done!\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sec_data_folder already exists\n",
            "working for:MMM.csv ...\n",
            "working for:ABT.csv ...\n",
            "working for:ABBV.csv ...\n",
            "working for:ABMD.csv ...\n",
            "working for:ACN.csv ...\n",
            "working for:ATVI.csv ...\n",
            "working for:ADBE.csv ...\n",
            "working for:AMD.csv ...\n",
            "working for:AAP.csv ...\n",
            "working for:AES.csv ...\n",
            "working for:AFL.csv ...\n",
            "working for:A.csv ...\n",
            "working for:APD.csv ...\n",
            "working for:AKAM.csv ...\n",
            "working for:ALK.csv ...\n",
            "working for:ALB.csv ...\n",
            "working for:ARE.csv ...\n",
            "working for:ALXN.csv ...\n",
            "working for:ALGN.csv ...\n",
            "working for:ALLE.csv ...\n",
            "working for:AGN.csv ...\n",
            "working for:ADS.csv ...\n",
            "working for:LNT.csv ...\n",
            "working for:ALL.csv ...\n",
            "working for:GOOG.csv ...\n",
            "working for:MO.csv ...\n",
            "working for:AMZN.csv ...\n",
            "working for:AMCR.csv ...\n",
            "working for:AEE.csv ...\n",
            "working for:AAL.csv ...\n",
            "working for:AEP.csv ...\n",
            "working for:AXP.csv ...\n",
            "working for:AIG.csv ...\n",
            "working for:AMT.csv ...\n",
            "working for:AWK.csv ...\n",
            "working for:AMP.csv ...\n",
            "working for:ABC.csv ...\n",
            "working for:AME.csv ...\n",
            "working for:AMGN.csv ...\n",
            "working for:APH.csv ...\n",
            "working for:ADI.csv ...\n",
            "working for:ANSS.csv ...\n",
            "working for:ANTM.csv ...\n",
            "working for:AON.csv ...\n",
            "working for:AOS.csv ...\n",
            "working for:APA.csv ...\n",
            "working for:AIV.csv ...\n",
            "working for:AAPL.csv ...\n",
            "working for:AMAT.csv ...\n",
            "working for:APTV.csv ...\n",
            "working for:ADM.csv ...\n",
            "working for:ANET.csv ...\n",
            "working for:AJG.csv ...\n",
            "working for:AIZ.csv ...\n",
            "working for:T.csv ...\n",
            "working for:ATO.csv ...\n",
            "working for:ADSK.csv ...\n",
            "working for:ADP.csv ...\n",
            "working for:AZO.csv ...\n",
            "working for:AVB.csv ...\n",
            "working for:AVY.csv ...\n",
            "working for:BKR.csv ...\n",
            "working for:BLL.csv ...\n",
            "working for:BAC.csv ...\n",
            "working for:BK.csv ...\n",
            "working for:BAX.csv ...\n",
            "working for:BDX.csv ...\n",
            "working for:BBY.csv ...\n",
            "working for:BIIB.csv ...\n",
            "working for:BLK.csv ...\n",
            "working for:BA.csv ...\n",
            "working for:BKNG.csv ...\n",
            "working for:BWA.csv ...\n",
            "working for:BXP.csv ...\n",
            "working for:BSX.csv ...\n",
            "working for:BMY.csv ...\n",
            "working for:AVGO.csv ...\n",
            "working for:BR.csv ...\n",
            "working for:CHRW.csv ...\n",
            "working for:COG.csv ...\n",
            "working for:CDNS.csv ...\n",
            "working for:CPB.csv ...\n",
            "working for:COF.csv ...\n",
            "working for:CPRI.csv ...\n",
            "working for:CAH.csv ...\n",
            "working for:KMX.csv ...\n",
            "working for:CCL.csv ...\n",
            "working for:CARR.csv ...\n",
            "working for:CAT.csv ...\n",
            "working for:CBOE.csv ...\n",
            "working for:CBRE.csv ...\n",
            "working for:CDW.csv ...\n",
            "working for:CE.csv ...\n",
            "working for:CNC.csv ...\n",
            "working for:CNP.csv ...\n",
            "working for:CTL.csv ...\n",
            "working for:CERN.csv ...\n",
            "working for:CF.csv ...\n",
            "working for:SCHW.csv ...\n",
            "working for:CHTR.csv ...\n",
            "working for:CVX.csv ...\n",
            "working for:CMG.csv ...\n",
            "working for:CB.csv ...\n",
            "working for:CHD.csv ...\n",
            "working for:CI.csv ...\n",
            "working for:CINF.csv ...\n",
            "working for:CTAS.csv ...\n",
            "working for:CSCO.csv ...\n",
            "working for:C.csv ...\n",
            "working for:CFG.csv ...\n",
            "working for:CTXS.csv ...\n",
            "working for:CLX.csv ...\n",
            "working for:CME.csv ...\n",
            "working for:CMS.csv ...\n",
            "working for:KO.csv ...\n",
            "working for:CTSH.csv ...\n",
            "working for:CL.csv ...\n",
            "working for:CMCSA.csv ...\n",
            "working for:CMA.csv ...\n",
            "working for:CAG.csv ...\n",
            "working for:CXO.csv ...\n",
            "working for:COP.csv ...\n",
            "working for:ED.csv ...\n",
            "working for:STZ.csv ...\n",
            "working for:COO.csv ...\n",
            "working for:CPRT.csv ...\n",
            "working for:GLW.csv ...\n",
            "working for:CTVA.csv ...\n",
            "working for:COST.csv ...\n",
            "working for:COTY.csv ...\n",
            "working for:CCI.csv ...\n",
            "working for:CSX.csv ...\n",
            "working for:CMI.csv ...\n",
            "working for:CVS.csv ...\n",
            "working for:DHI.csv ...\n",
            "working for:DHR.csv ...\n",
            "working for:DRI.csv ...\n",
            "working for:DVA.csv ...\n",
            "working for:DE.csv ...\n",
            "working for:DAL.csv ...\n",
            "working for:XRAY.csv ...\n",
            "working for:DVN.csv ...\n",
            "working for:FANG.csv ...\n",
            "working for:DLR.csv ...\n",
            "working for:DFS.csv ...\n",
            "working for:DISCA.csv ...\n",
            "working for:DISCK.csv ...\n",
            "working for:DISH.csv ...\n",
            "working for:DG.csv ...\n",
            "working for:DLTR.csv ...\n",
            "working for:D.csv ...\n",
            "working for:DOV.csv ...\n",
            "working for:DOW.csv ...\n",
            "working for:DTE.csv ...\n",
            "working for:DUK.csv ...\n",
            "working for:DRE.csv ...\n",
            "working for:DD.csv ...\n",
            "working for:DXC.csv ...\n",
            "working for:ETFC.csv ...\n",
            "working for:EMN.csv ...\n",
            "working for:ETN.csv ...\n",
            "working for:EBAY.csv ...\n",
            "working for:ECL.csv ...\n",
            "working for:EIX.csv ...\n",
            "working for:EW.csv ...\n",
            "working for:EA.csv ...\n",
            "working for:EMR.csv ...\n",
            "working for:ETR.csv ...\n",
            "working for:EOG.csv ...\n",
            "working for:EFX.csv ...\n",
            "working for:EQIX.csv ...\n",
            "working for:EQR.csv ...\n",
            "working for:ESS.csv ...\n",
            "working for:EL.csv ...\n",
            "working for:EVRG.csv ...\n",
            "working for:ES.csv ...\n",
            "working for:RE.csv ...\n",
            "working for:EXC.csv ...\n",
            "working for:EXPE.csv ...\n",
            "working for:EXPD.csv ...\n",
            "working for:EXR.csv ...\n",
            "working for:XOM.csv ...\n",
            "working for:FFIV.csv ...\n",
            "working for:FB.csv ...\n",
            "working for:FAST.csv ...\n",
            "working for:FRT.csv ...\n",
            "working for:FDX.csv ...\n",
            "working for:FIS.csv ...\n",
            "working for:FITB.csv ...\n",
            "working for:FE.csv ...\n",
            "working for:FRC.csv ...\n",
            "working for:FISV.csv ...\n",
            "working for:FLT.csv ...\n",
            "working for:FLIR.csv ...\n",
            "working for:FLS.csv ...\n",
            "working for:FMC.csv ...\n",
            "working for:F.csv ...\n",
            "working for:FTNT.csv ...\n",
            "working for:FTV.csv ...\n",
            "working for:FBHS.csv ...\n",
            "working for:FOXA.csv ...\n",
            "working for:FOX.csv ...\n",
            "working for:BEN.csv ...\n",
            "working for:FCX.csv ...\n",
            "working for:GPS.csv ...\n",
            "working for:GRMN.csv ...\n",
            "working for:IT.csv ...\n",
            "working for:GD.csv ...\n",
            "working for:GE.csv ...\n",
            "working for:GIS.csv ...\n",
            "working for:GM.csv ...\n",
            "working for:GPC.csv ...\n",
            "working for:GILD.csv ...\n",
            "working for:GL.csv ...\n",
            "working for:GPN.csv ...\n",
            "working for:GS.csv ...\n",
            "working for:GWW.csv ...\n",
            "working for:HRB.csv ...\n",
            "working for:HAL.csv ...\n",
            "working for:HBI.csv ...\n",
            "working for:HOG.csv ...\n",
            "working for:HIG.csv ...\n",
            "working for:HAS.csv ...\n",
            "working for:HCA.csv ...\n",
            "working for:PEAK.csv ...\n",
            "working for:HP.csv ...\n",
            "working for:HSIC.csv ...\n",
            "working for:HSY.csv ...\n",
            "working for:HES.csv ...\n",
            "working for:HPE.csv ...\n",
            "working for:HLT.csv ...\n",
            "working for:HFC.csv ...\n",
            "working for:HOLX.csv ...\n",
            "working for:HD.csv ...\n",
            "working for:HON.csv ...\n",
            "working for:HRL.csv ...\n",
            "working for:HST.csv ...\n",
            "working for:HWM.csv ...\n",
            "working for:HPQ.csv ...\n",
            "working for:HUM.csv ...\n",
            "working for:HBAN.csv ...\n",
            "working for:HII.csv ...\n",
            "working for:IEX.csv ...\n",
            "working for:IDXX.csv ...\n",
            "working for:INFO.csv ...\n",
            "working for:ITW.csv ...\n",
            "working for:ILMN.csv ...\n",
            "working for:INCY.csv ...\n",
            "working for:IR.csv ...\n",
            "working for:INTC.csv ...\n",
            "working for:ICE.csv ...\n",
            "working for:IBM.csv ...\n",
            "working for:IP.csv ...\n",
            "working for:IPG.csv ...\n",
            "working for:IFF.csv ...\n",
            "working for:INTU.csv ...\n",
            "working for:ISRG.csv ...\n",
            "working for:IVZ.csv ...\n",
            "working for:IPGP.csv ...\n",
            "working for:IQV.csv ...\n",
            "working for:IRM.csv ...\n",
            "working for:JKHY.csv ...\n",
            "working for:J.csv ...\n",
            "working for:JBHT.csv ...\n",
            "working for:SJM.csv ...\n",
            "working for:JNJ.csv ...\n",
            "working for:JCI.csv ...\n",
            "working for:JPM.csv ...\n",
            "working for:JNPR.csv ...\n",
            "working for:KSU.csv ...\n",
            "working for:K.csv ...\n",
            "working for:KEY.csv ...\n",
            "working for:KEYS.csv ...\n",
            "working for:KMB.csv ...\n",
            "working for:KIM.csv ...\n",
            "working for:KMI.csv ...\n",
            "working for:KLAC.csv ...\n",
            "working for:KSS.csv ...\n",
            "working for:KHC.csv ...\n",
            "working for:KR.csv ...\n",
            "working for:LB.csv ...\n",
            "working for:LHX.csv ...\n",
            "working for:LH.csv ...\n",
            "working for:LRCX.csv ...\n",
            "working for:LW.csv ...\n",
            "working for:LVS.csv ...\n",
            "working for:LEG.csv ...\n",
            "working for:LDOS.csv ...\n",
            "working for:LEN.csv ...\n",
            "working for:LLY.csv ...\n",
            "working for:LNC.csv ...\n",
            "working for:LIN.csv ...\n",
            "working for:LYV.csv ...\n",
            "working for:LKQ.csv ...\n",
            "working for:LMT.csv ...\n",
            "working for:L.csv ...\n",
            "working for:LOW.csv ...\n",
            "working for:LYB.csv ...\n",
            "working for:MTB.csv ...\n",
            "working for:MRO.csv ...\n",
            "working for:MPC.csv ...\n",
            "working for:MKTX.csv ...\n",
            "working for:MAR.csv ...\n",
            "working for:MMC.csv ...\n",
            "working for:MLM.csv ...\n",
            "working for:MAS.csv ...\n",
            "working for:MA.csv ...\n",
            "working for:MKC.csv ...\n",
            "working for:MXIM.csv ...\n",
            "working for:MCD.csv ...\n",
            "working for:MCK.csv ...\n",
            "working for:MDT.csv ...\n",
            "working for:MRK.csv ...\n",
            "working for:MET.csv ...\n",
            "working for:MTD.csv ...\n",
            "working for:MGM.csv ...\n",
            "working for:MCHP.csv ...\n",
            "working for:MU.csv ...\n",
            "working for:MSFT.csv ...\n",
            "working for:MAA.csv ...\n",
            "working for:MHK.csv ...\n",
            "working for:TAP.csv ...\n",
            "working for:MDLZ.csv ...\n",
            "working for:MNST.csv ...\n",
            "working for:MCO.csv ...\n",
            "working for:MS.csv ...\n",
            "working for:MSI.csv ...\n",
            "working for:MSCI.csv ...\n",
            "working for:MYL.csv ...\n",
            "working for:NDAQ.csv ...\n",
            "working for:NOV.csv ...\n",
            "working for:NTAP.csv ...\n",
            "working for:NFLX.csv ...\n",
            "working for:NWL.csv ...\n",
            "working for:NEM.csv ...\n",
            "working for:NWSA.csv ...\n",
            "working for:NWS.csv ...\n",
            "working for:NEE.csv ...\n",
            "working for:NLSN.csv ...\n",
            "working for:NKE.csv ...\n",
            "working for:NI.csv ...\n",
            "working for:NBL.csv ...\n",
            "working for:JWN.csv ...\n",
            "working for:NSC.csv ...\n",
            "working for:NTRS.csv ...\n",
            "working for:NOC.csv ...\n",
            "working for:NLOK.csv ...\n",
            "working for:NCLH.csv ...\n",
            "working for:NRG.csv ...\n",
            "working for:NUE.csv ...\n",
            "working for:NVDA.csv ...\n",
            "working for:NVR.csv ...\n",
            "working for:ORLY.csv ...\n",
            "working for:OXY.csv ...\n",
            "working for:ODFL.csv ...\n",
            "working for:OMC.csv ...\n",
            "working for:OKE.csv ...\n",
            "working for:ORCL.csv ...\n",
            "working for:OTIS.csv ...\n",
            "working for:PCAR.csv ...\n",
            "working for:PKG.csv ...\n",
            "working for:PH.csv ...\n",
            "working for:PAYX.csv ...\n",
            "working for:PAYC.csv ...\n",
            "working for:PYPL.csv ...\n",
            "working for:PNR.csv ...\n",
            "working for:PBCT.csv ...\n",
            "working for:PEP.csv ...\n",
            "working for:PKI.csv ...\n",
            "working for:PRGO.csv ...\n",
            "working for:PFE.csv ...\n",
            "working for:PM.csv ...\n",
            "working for:PSX.csv ...\n",
            "working for:PNW.csv ...\n",
            "working for:PXD.csv ...\n",
            "working for:PNC.csv ...\n",
            "working for:PPG.csv ...\n",
            "working for:PPL.csv ...\n",
            "working for:PFG.csv ...\n",
            "working for:PG.csv ...\n",
            "working for:PGR.csv ...\n",
            "working for:PLD.csv ...\n",
            "working for:PRU.csv ...\n",
            "working for:PEG.csv ...\n",
            "working for:PSA.csv ...\n",
            "working for:PHM.csv ...\n",
            "working for:PVH.csv ...\n",
            "working for:QRVO.csv ...\n",
            "working for:PWR.csv ...\n",
            "working for:QCOM.csv ...\n",
            "working for:DGX.csv ...\n",
            "working for:RL.csv ...\n",
            "working for:RJF.csv ...\n",
            "working for:RTX.csv ...\n",
            "working for:O.csv ...\n",
            "working for:REG.csv ...\n",
            "working for:REGN.csv ...\n",
            "working for:RF.csv ...\n",
            "working for:RSG.csv ...\n",
            "working for:RMD.csv ...\n",
            "working for:RHI.csv ...\n",
            "working for:ROK.csv ...\n",
            "working for:ROL.csv ...\n",
            "working for:ROP.csv ...\n",
            "working for:ROST.csv ...\n",
            "working for:RCL.csv ...\n",
            "working for:SPGI.csv ...\n",
            "working for:CRM.csv ...\n",
            "working for:SBAC.csv ...\n",
            "working for:SLB.csv ...\n",
            "working for:STX.csv ...\n",
            "working for:SEE.csv ...\n",
            "working for:SRE.csv ...\n",
            "working for:NOW.csv ...\n",
            "working for:SHW.csv ...\n",
            "working for:SPG.csv ...\n",
            "working for:SWKS.csv ...\n",
            "working for:SLG.csv ...\n",
            "working for:SNA.csv ...\n",
            "working for:SO.csv ...\n",
            "working for:LUV.csv ...\n",
            "working for:SWK.csv ...\n",
            "working for:SBUX.csv ...\n",
            "working for:STT.csv ...\n",
            "working for:STE.csv ...\n",
            "working for:SYK.csv ...\n",
            "working for:SIVB.csv ...\n",
            "working for:SYF.csv ...\n",
            "working for:SNPS.csv ...\n",
            "working for:SYY.csv ...\n",
            "working for:TMUS.csv ...\n",
            "working for:TROW.csv ...\n",
            "working for:TTWO.csv ...\n",
            "working for:TPR.csv ...\n",
            "working for:TGT.csv ...\n",
            "working for:TEL.csv ...\n",
            "working for:FTI.csv ...\n",
            "working for:TFX.csv ...\n",
            "working for:TXN.csv ...\n",
            "working for:TXT.csv ...\n",
            "working for:TMO.csv ...\n",
            "working for:TIF.csv ...\n",
            "working for:TJX.csv ...\n",
            "working for:TSCO.csv ...\n",
            "working for:TT.csv ...\n",
            "working for:TDG.csv ...\n",
            "working for:TRV.csv ...\n",
            "working for:TFC.csv ...\n",
            "working for:TWTR.csv ...\n",
            "working for:TSN.csv ...\n",
            "working for:UDR.csv ...\n",
            "working for:ULTA.csv ...\n",
            "working for:USB.csv ...\n",
            "working for:UAA.csv ...\n",
            "working for:UA.csv ...\n",
            "working for:UNP.csv ...\n",
            "working for:UAL.csv ...\n",
            "working for:UNH.csv ...\n",
            "working for:UPS.csv ...\n",
            "working for:URI.csv ...\n",
            "working for:UHS.csv ...\n",
            "working for:UNM.csv ...\n",
            "working for:VFC.csv ...\n",
            "working for:VLO.csv ...\n",
            "working for:VAR.csv ...\n",
            "working for:VTR.csv ...\n",
            "working for:VRSN.csv ...\n",
            "working for:VRSK.csv ...\n",
            "working for:VZ.csv ...\n",
            "working for:VRTX.csv ...\n",
            "working for:VIAC.csv ...\n",
            "working for:V.csv ...\n",
            "working for:VNO.csv ...\n",
            "working for:VMC.csv ...\n",
            "working for:WRB.csv ...\n",
            "working for:WAB.csv ...\n",
            "working for:WMT.csv ...\n",
            "working for:WBA.csv ...\n",
            "working for:DIS.csv ...\n",
            "working for:WM.csv ...\n",
            "working for:WAT.csv ...\n",
            "working for:WEC.csv ...\n",
            "working for:WFC.csv ...\n",
            "working for:WELL.csv ...\n",
            "working for:WDC.csv ...\n",
            "working for:WU.csv ...\n",
            "working for:WRK.csv ...\n",
            "working for:WY.csv ...\n",
            "working for:WHR.csv ...\n",
            "working for:WMB.csv ...\n",
            "working for:WLTW.csv ...\n",
            "working for:WYNN.csv ...\n",
            "working for:XEL.csv ...\n",
            "working for:XRX.csv ...\n",
            "working for:XLNX.csv ...\n",
            "working for:XYL.csv ...\n",
            "working for:YUM.csv ...\n",
            "working for:ZBRA.csv ...\n",
            "working for:ZBH.csv ...\n",
            "working for:ZION.csv ...\n",
            "working for:ZTS.csv ...\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}