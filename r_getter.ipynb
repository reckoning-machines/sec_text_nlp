{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r_getter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLCRrpjtUFczV8S+vBs3Az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reckoning-machines/sec_text_nlp/blob/master/r_getter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxREunso0REA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "19ecf37d-5085-4de6-b025-164595d745ad"
      },
      "source": [
        "# why use R here?  \n",
        "# edgarWebR pulls sections really well\n",
        "# do i want to find a python library for the same thing?  sure.\n",
        "# do i want to write a python utils file for the same thing?  not really but we may have to!\n",
        "\n",
        "# activate R magic\n",
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The rpy2.ipython extension is already loaded. To reload it, use:\n",
            "  %reload_ext rpy2.ipython\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x4-h6m0x-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9a9e9cf9-774d-41a7-f407-4d28e42f5e7a"
      },
      "source": [
        "%%R\n",
        "\n",
        "#R GETTER.  For this example, only one ticker (head,1) is pulled \n",
        "#file is saved into local \n",
        "#then python code cell pushes file to google sheet\n",
        "\n",
        "devtools::install_github(\"mwaldstein/edgarWebR\")\n",
        "#devtools::install_github(\"tidyverse/googlesheets4\")\n",
        "devtools::install_github(\"r-lib/xml2\") #this for edgarWebR \n",
        "#devtools::install_version(\"xml2\", version = \"1.2.2\", repos = \"http://cran.us.r-project.org\")\n",
        "#file creates a set of csv from ticker list which include metadata & text data.\n",
        "\n",
        "library(edgarWebR) #this is an up to date library with an active maintainer.\n",
        "library(xml2)\n",
        "library(knitr)\n",
        "library(dplyr)\n",
        "library(purrr)\n",
        "library(rvest)\n",
        "library(tidyr)\n",
        "library(readr)\n",
        "\n",
        "#library(log4r) TODO logging file.\n",
        "#library(googlesheets4)\n",
        "#gs4_deauth()\n",
        "#tickers list\n",
        "#str_sheet <- \"1_xcDVKjR2jqE-w5LqxIWnrDYstpSrE5nFSSY0WXNOVE\"\n",
        "#df_tickers <- read_sheet(str_sheet)\n",
        "\n",
        "get_filings_links <-function(str_ticker) {\n",
        "  df_filings <- company_filings(str_ticker, type = \"10-\", count = 20)\n",
        "  df_filings <- df_filings[df_filings$type == \"10-K\" | df_filings$type == \"10-Q\", ]\n",
        "  df_filing_infos <- map_df(df_filings$href, filing_information)\n",
        "  df_filings <- bind_cols(df_filings, df_filing_infos)\n",
        "  return(head(as_tibble(df_filings),6))\n",
        "}\n",
        "\n",
        "df_tickers <- read_csv('test_ticker_list.csv')\n",
        "\n",
        "#file creates a set of csv from ticker list which include metadata & text data.\n",
        "df_tickers <- head(df_tickers,1)\n",
        "\n",
        "get_section_text <- function(str_href, str_section, str_search) {\n",
        "  \n",
        "  df_filing_documents <- filing_documents(str_href)\n",
        "  str_doc_href <- df_filing_documents[df_filing_documents$type == \"10-K\" | df_filing_documents$type == \"10-Q\",]$href\n",
        "  doc <- parse_filing(str_doc_href)\n",
        "\n",
        "  df_txt <- doc[grepl(str_section, doc$item.name, ignore.case = TRUE) & grepl(str_search, doc$item.name, ignore.case = TRUE), ] # only discussion for now\n",
        "  #we could do some text preprocessing here.\n",
        "\n",
        "  df_txt <- as_tibble(df_txt) %>%\n",
        "    mutate(section = str_search)\n",
        "\n",
        "  return(df_txt)\n",
        "}\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Skipping install of 'edgarWebR' from a github remote, the SHA1 (e7fa70ea) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\n",
            "R[write to console]: Skipping install of 'xml2' from a github remote, the SHA1 (9928883d) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\n",
            "R[write to console]: Parsed with column specification:\n",
            "cols(\n",
            "  X1 = col_double(),\n",
            "  `GICS Sector` = col_character(),\n",
            "  Symbol = col_character(),\n",
            "  mkt_cap = col_double()\n",
            ")\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYcX52F7_pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2351f7f2-635e-4c1c-d33f-5e0e0d19a89c"
      },
      "source": [
        "%%R\n",
        "\n",
        "get_document_text <- function(str_ticker, force = FALSE) { #not using force yet\n",
        "  start_time <- Sys.time()\n",
        "  \n",
        "  print(str_ticker)\n",
        "  \n",
        "  str_write_name <- str_ticker \n",
        "  #paste0(\"~/data/\",str_ticker,\"_sec_text\")\n",
        "\n",
        "  print(\"get filings links ...\")\n",
        "\n",
        "  df_filings <- get_filings_links(str_ticker)\n",
        "\n",
        "  #print(df_filings)\n",
        "\n",
        "  print(\"get section text ...\")\n",
        "\n",
        "  df_data <- (df_filings) %>% \n",
        "    rowwise() %>%\n",
        "    mutate(nest_discussion = map(.x = href, str_section = 'item 2|item 7',str_search = 'discussion', .f = get_section_text)) %>%\n",
        "    mutate(nest_qualitative = map(.x = href, str_section = 'item 3|item 7a', str_search = 'qualitative', .f = get_section_text)) %>%\n",
        "    mutate(nest_controls = map(.x = href, str_section = 'item 4|item 9a',str_search = 'controls', .f = get_section_text)) %>%\n",
        "    mutate(nest_risk = map(.x = href, str_section = 'item 1',str_search = 'risk factors', .f = get_section_text)) %>%\n",
        "    ungroup() %>%\n",
        "    select(period_date,filing_date,type,form_name,documents,nest_discussion,nest_qualitative,nest_controls,nest_risk) %>%\n",
        "    group_by(period_date) %>%\n",
        "    arrange(desc(period_date))\n",
        "  \n",
        "  #jenky - find a rowwise application\n",
        "  a <- df_data %>% \n",
        "    select(period_date,filing_date,type,form_name,documents,nest_discussion) %>%\n",
        "    unnest(nest_discussion)\n",
        "  b <- df_data %>% \n",
        "    select(period_date,filing_date,type,form_name,documents,nest_qualitative) %>%\n",
        "    unnest(nest_qualitative)\n",
        "  c <- df_data %>% \n",
        "    select(period_date,filing_date,type,form_name,documents,nest_controls) %>%\n",
        "    unnest(nest_controls)\n",
        "  d <- df_data %>% \n",
        "    select(period_date,filing_date,type,form_name,documents,nest_risk) %>%\n",
        "    unnest(nest_risk)\n",
        "\n",
        "  print(\"write to local csv  ...\")\n",
        "\n",
        "  #ss <- gs4_create(str_write_name)\n",
        "  \n",
        "  #df_data <- rbind(a,b,c,d) %>%\n",
        "  #  googlesheets4::sheet_write(ss, sheet = \"sec_data\")\n",
        "  \n",
        "  df_data <- rbind(a,b,c,d) %>%\n",
        "    write_csv(paste0(str_write_name,\".csv\"))\n",
        "\n",
        "  end_time <- Sys.time()\n",
        "\n",
        "  print(end_time - start_time)\n",
        "\n",
        "  return(df_data)\n",
        "}\n",
        "\n",
        "#long run.\n",
        "df_data <- map_df(df_tickers$Symbol, get_document_text)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] \"GOOG\"\n",
            "[1] \"get filings links ...\"\n",
            "[1] \"get section text ...\"\n",
            "[1] \"write to local csv  ...\"\n",
            "Time difference of 1.032341 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4BkP1_E2F0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#save single file to google sheets\n",
        "#to do: loop thru all tickers in dir.\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_data = pd.read_csv('GOOG.csv')\n",
        "\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "title = 'sec_data'\n",
        "gc.create(title)  # if not exist\n",
        "sheet = gc.open(title).sheet1\n",
        "set_with_dataframe(sheet, df_data) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}