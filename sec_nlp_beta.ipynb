{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sec_nlp_beta.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAc7igUURvmsrCnEWV5zuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reckoning-machines/sec_text_nlp/blob/master/sec_nlp_beta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PEGuwlTGxfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://gist.github.com/Joshua1989/dc7e60aa487430ea704a8cb3f2c5d6a6\n",
        "!mkdir sec_data_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVX4_nlmIYmf",
        "colab_type": "code",
        "outputId": "a70e8c29-b18d-47e1-dbc1-82220e809320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://gist.github.com/dc7e60aa487430ea704a8cb3f2c5d6a6.git /tmp/colab_util_repo\n",
        "!mv /tmp/colab_util_repo/colab_util.py colab_util.py \n",
        "!rm -r /tmp/colab_util_repo\n",
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/colab_util_repo'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOOMZczJm3Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_handler.download('test_ticker_list.csv', target_path='test_ticker_list.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa70Oj6pnJsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "94607a89-076a-4f62-a50b-05c5acc8563b"
      },
      "source": [
        "import pandas as pd\n",
        "df_tickers = pd.read_csv('test_ticker_list.csv')\n",
        "\n",
        "for i, row in df_tickers.iterrows():\n",
        "  str_ticker = row['Symbol']\n",
        "  \n",
        "  print('working for:'+str_ticker+\"...\")\n",
        "\n",
        "  str_to_file = 'sec_data_folder/'+str_ticker+'.csv'\n",
        "  str_from_file = '/sec_data_folder/'+str_ticker+'.csv'\n",
        "  drive_handler.download(str_to_file, target_path=str_from_file)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working for:GOOG...\n",
            "working for:FB...\n",
            "working for:AMZN...\n",
            "working for:HD...\n",
            "working for:WMT...\n",
            "working for:PG...\n",
            "working for:XOM...\n",
            "working for:CVX...\n",
            "working for:JPM...\n",
            "working for:BAC...\n",
            "working for:JNJ...\n",
            "working for:UNH...\n",
            "working for:LMT...\n",
            "working for:UNP...\n",
            "working for:MSFT...\n",
            "working for:AAPL...\n",
            "working for:LIN...\n",
            "working for:ECL...\n",
            "working for:AMT...\n",
            "working for:CCI...\n",
            "working for:NEE...\n",
            "working for:D...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiOQAktZoTpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7c932de4-2806-4458-8942-1b06c9d30acf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk import tokenize\n",
        "\n",
        "#replace with your own list of words ... like covid or delay or cancel (it lowercases automatically)\n",
        "FIND_WORDS = ['movie',\n",
        "              'acting',\n",
        "              'story']\n",
        "\n",
        "def check_if_list_found_in_text(text, words=[], return_offset=False, lower_text=True):\n",
        "    result = []\n",
        "    text = (\n",
        "        \" \"\n",
        "        + text.replace(\"_\", \" \")\n",
        "        .replace(\"-\", \" \")\n",
        "        .replace(\",\", \" \")\n",
        "        .replace(\";\", \" \")\n",
        "        .replace('\"', \" \")\n",
        "        .replace(\":\", \" \")\n",
        "        .replace(\".\", \" \")\n",
        "        + \" \"\n",
        "    )\n",
        "    if lower_text:\n",
        "        text = text.lower()\n",
        "    for word in words:\n",
        "        word = (\n",
        "            \" \"\n",
        "            + word.replace(\"_\", \" \")\n",
        "            .replace(\"-\", \" \")\n",
        "            .replace(\",\", \" \")\n",
        "            .replace(\";\", \" \")\n",
        "            .replace('\"', \" \")\n",
        "            .replace(\":\", \" \")\n",
        "            .replace(\".\", \" \")\n",
        "            + \" \"\n",
        "        )\n",
        "        if lower_text:\n",
        "            word = word.lower()\n",
        "        if word in text:\n",
        "            if return_offset:\n",
        "                offset = text.find(word)\n",
        "                # offset = offset if not offset else offset-1\n",
        "                result.append(offset)\n",
        "            else:\n",
        "                result.append(word.strip())\n",
        "    return result\n",
        "def filter_stopwords(sent):\n",
        "    stop_words = set(stopwords.words('english'))   \n",
        "    word_tokens = word_tokenize(sent)   \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)\n",
        "    return ' '.join(filtered_sentence)\n",
        "\n",
        "def df_from_text(text):\n",
        "    sentence_list = tokenize.sent_tokenize(text)\n",
        "    sentence_list\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    list_df = []\n",
        "    for sentence in sentence_list:\n",
        "        sentence = filter_stopwords(sentence)\n",
        "        list_found = check_if_list_found_in_text(sentence,FIND_WORDS)\n",
        "        num_found = len(list_found)\n",
        "        ss = sid.polarity_scores(sentence)\n",
        "        df = pd.DataFrame.from_dict(ss,orient = \"index\").T\n",
        "        df['text'] = sentence\n",
        "        df['keywords_found'] = num_found \n",
        "        list_df.append(df)\n",
        "    return pd.concat(list_df)\n",
        "\n",
        "df_text = pd.read_csv(\"sec_data_folder/WMT.csv\") #replace with your own dataset\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6BA5jNLpuMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_discussion = df_text[df_text['section']=='discussion']\n",
        "\n",
        "list_df = []\n",
        "for i,row in df_discussion.iterrows():\n",
        "    df = df_from_text(row['text']) #replace with your own text column name\n",
        "    df['id'] = i #this would be \"slack message id\" basically\n",
        "    df['period_date'] = row['period_date']\n",
        "    df['type'] = row['type']\n",
        "    df['section'] = row['section']\n",
        "    list_df.append(df)\n",
        "\n",
        "df_sentence_text_scores = pd.concat(list_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaJBv_zQqIOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fcbd564d-56b1-4892-c5f1-0a1abecc8fac"
      },
      "source": [
        "df_discussion.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>period_date</th>\n",
              "      <th>filing_date</th>\n",
              "      <th>type</th>\n",
              "      <th>form_name</th>\n",
              "      <th>documents</th>\n",
              "      <th>text</th>\n",
              "      <th>part.name</th>\n",
              "      <th>item.name</th>\n",
              "      <th>section</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-31T00:00:00Z</td>\n",
              "      <td>2020-03-20T00:00:00Z</td>\n",
              "      <td>10-K</td>\n",
              "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
              "      <td>109</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>PART II</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-31T00:00:00Z</td>\n",
              "      <td>2020-03-20T00:00:00Z</td>\n",
              "      <td>10-K</td>\n",
              "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
              "      <td>109</td>\n",
              "      <td>Overview</td>\n",
              "      <td>PART II</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-31T00:00:00Z</td>\n",
              "      <td>2020-03-20T00:00:00Z</td>\n",
              "      <td>10-K</td>\n",
              "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
              "      <td>109</td>\n",
              "      <td>This discussion, which presents our results fo...</td>\n",
              "      <td>PART II</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-31T00:00:00Z</td>\n",
              "      <td>2020-03-20T00:00:00Z</td>\n",
              "      <td>10-K</td>\n",
              "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
              "      <td>109</td>\n",
              "      <td>Throughout this Item 7, we discuss segment ope...</td>\n",
              "      <td>PART II</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-31T00:00:00Z</td>\n",
              "      <td>2020-03-20T00:00:00Z</td>\n",
              "      <td>10-K</td>\n",
              "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
              "      <td>109</td>\n",
              "      <td>Management also measures the results of compar...</td>\n",
              "      <td>PART II</td>\n",
              "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            period_date  ...     section\n",
              "0  2020-01-31T00:00:00Z  ...  discussion\n",
              "1  2020-01-31T00:00:00Z  ...  discussion\n",
              "2  2020-01-31T00:00:00Z  ...  discussion\n",
              "3  2020-01-31T00:00:00Z  ...  discussion\n",
              "4  2020-01-31T00:00:00Z  ...  discussion\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}